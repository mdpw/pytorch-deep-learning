{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93313539",
   "metadata": {},
   "source": [
    "# CIFAR-10 Classification using Fully Connected Neural Network (FCN)\n",
    "\n",
    "This notebook implements a Fully Connected Neural Network (FCN) using PyTorch to classify images from the CIFAR-10 dataset. This is intended to be a baseline for comparison with a Convolutional Neural Network (CNN) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "686c4ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f70586",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbae80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42487bd6",
   "metadata": {},
   "source": [
    "## Define the Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc2e705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3*32*32, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 256)\n",
    "        self.fc4 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*32*32)  # Flatten the image\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "net = FCN().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b092a512",
   "metadata": {},
   "source": [
    "## Define Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bf3414",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3b70aa",
   "metadata": {},
   "source": [
    "## Train the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e2a66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 100] loss: 0.580\n",
      "[1, 200] loss: 0.595\n",
      "[1, 300] loss: 0.644\n",
      "[1, 400] loss: 0.640\n",
      "[1, 500] loss: 0.661\n",
      "Epoch 1 Test Accuracy: 53.94%\n",
      "[2, 100] loss: 0.527\n",
      "[2, 200] loss: 0.553\n",
      "[2, 300] loss: 0.560\n",
      "[2, 400] loss: 0.582\n",
      "[2, 500] loss: 0.636\n",
      "Epoch 2 Test Accuracy: 54.24%\n",
      "[3, 100] loss: 0.453\n",
      "[3, 200] loss: 0.494\n",
      "[3, 300] loss: 0.531\n",
      "[3, 400] loss: 0.529\n",
      "[3, 500] loss: 0.534\n",
      "Epoch 3 Test Accuracy: 53.66%\n",
      "[4, 100] loss: 0.403\n",
      "[4, 200] loss: 0.428\n",
      "[4, 300] loss: 0.451\n",
      "[4, 400] loss: 0.482\n",
      "[4, 500] loss: 0.512\n",
      "Epoch 4 Test Accuracy: 53.31%\n",
      "[5, 100] loss: 0.369\n",
      "[5, 200] loss: 0.391\n",
      "[5, 300] loss: 0.436\n",
      "[5, 400] loss: 0.454\n",
      "[5, 500] loss: 0.471\n",
      "Epoch 5 Test Accuracy: 53.22%\n",
      "[6, 100] loss: 0.340\n",
      "[6, 200] loss: 0.382\n",
      "[6, 300] loss: 0.409\n",
      "[6, 400] loss: 0.412\n",
      "[6, 500] loss: 0.435\n",
      "Epoch 6 Test Accuracy: 53.89%\n",
      "[7, 100] loss: 0.314\n",
      "[7, 200] loss: 0.334\n",
      "[7, 300] loss: 0.376\n",
      "[7, 400] loss: 0.385\n",
      "[7, 500] loss: 0.409\n",
      "Epoch 7 Test Accuracy: 53.64%\n",
      "[8, 100] loss: 0.295\n",
      "[8, 200] loss: 0.324\n",
      "[8, 300] loss: 0.341\n",
      "[8, 400] loss: 0.384\n",
      "[8, 500] loss: 0.400\n",
      "Epoch 8 Test Accuracy: 52.93%\n",
      "[9, 100] loss: 0.295\n",
      "[9, 200] loss: 0.284\n",
      "[9, 300] loss: 0.329\n",
      "[9, 400] loss: 0.359\n",
      "[9, 500] loss: 0.370\n",
      "Epoch 9 Test Accuracy: 54.62%\n",
      "[10, 100] loss: 0.271\n",
      "[10, 200] loss: 0.307\n",
      "[10, 300] loss: 0.309\n",
      "[10, 400] loss: 0.328\n",
      "[10, 500] loss: 0.348\n",
      "Epoch 10 Test Accuracy: 53.72%\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1}] loss: {running_loss / 100:.3f}\")\n",
    "            writer.add_scalar(\"training loss\", running_loss / 100, epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "    \n",
    "    # Evaluate on test data after each epoch\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for test_data in testloader:\n",
    "            test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "            test_outputs = net(test_images)\n",
    "            _, predicted = torch.max(test_outputs.data, 1)\n",
    "            total += test_labels.size(0)\n",
    "            correct += (predicted == test_labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch + 1} Test Accuracy: {accuracy:.2f}%\")\n",
    "    writer.add_scalar(\"Test Accuracy\", accuracy, epoch)\n",
    "writer.close()\n",
    "print(\"Finished Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110881db",
   "metadata": {},
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbdc4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 53.72%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
