{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumani\n",
    "# https://www.linkedin.com/in/sumanaruban/\n",
    "# https://github.com/Sumanaruban\n",
    "# 20-7-2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook explains the concepts of overfitting and underfitting, common issues encountered when training machine learning and deep learning models.\n",
    "\n",
    "In machine learning, our goal is to develop models that can generalize well to unseen data. However, two common pitfalls can hinder this:\n",
    "\n",
    "- Underfitting: The model is too simple to learn the underlying pattern in the training data.\n",
    "\n",
    "- Overfitting: The model learns the training data too well, including the noise, and fails to generalize to new data.\n",
    "\n",
    "In this notebook, you will observe both phenomena through visual and coding experiments using synthetic data and neural networks in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for reproducibility\n",
    "np.random.seed(0)\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate quadratic data with noise\n",
    "def generate_data(n_samples=100):\n",
    "    X = np.linspace(-10, 10, n_samples)\n",
    "    y = 0.5 * X**2 + 3 * X + 10 + np.random.randn(n_samples) * 10  # Quadratic pattern with noise\n",
    "    # y = 0.5 * X**2 + 3 * X + 10 # Quadratic pattern without noise\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_data()\n",
    "\n",
    "# Plot the generated data\n",
    "plt.scatter(X, y, label='Data points')\n",
    "plt.title('Quadratic Data with Noise')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we’re using has a clear pattern, along with some noise. This allows us to test how well different models capture the true trend versus overreacting to random fluctuations.\n",
    "\n",
    "- If a model fails to follow even the clear trend, it's underfitting.\n",
    "\n",
    "- If a model bends too much to fit every noisy point, it's overfitting.\n",
    "\n",
    "The goal is to find a model that fits the signal, not the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverfittingModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OverfittingModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 128)\n",
    "        self.fc4 = nn.Linear(128, 32)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        return self.fc5(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, num_epochs=1000, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(1)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(model, X, y, title):\n",
    "    model.eval()\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).unsqueeze(1)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_tensor).numpy()\n",
    "\n",
    "    plt.scatter(X, y, label='Data points')\n",
    "    plt.plot(X, y_pred, color='red', label='Model prediction')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting model\n",
    "linear_model = LinearModel()\n",
    "linear_model = train_model(linear_model, X, y, num_epochs=1000)\n",
    "\n",
    "# Plot results for underfitting model\n",
    "plot_model(linear_model, X, y, 'Underfitting Model (Linear Regression)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting model\n",
    "overfitting_model = OverfittingModel()\n",
    "overfitting_model = train_model(overfitting_model, X, y, num_epochs=1000)\n",
    "\n",
    "# Plot results for overfitting model\n",
    "plot_model(overfitting_model, X, y, 'Overfitting Model (Deep Neural Network)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdealModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IdealModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ideal model\n",
    "ideal_model = IdealModel()\n",
    "ideal_model = train_model(ideal_model, X, y, num_epochs=1000)\n",
    "\n",
    "plot_model(ideal_model, X, y, 'Ideal Model (Polynomial Regression)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look carefully at the training and validation losses:\n",
    "\n",
    "- If both are high → underfitting (model can’t capture data patterns).\n",
    "\n",
    "- If training loss is low but validation loss is high → overfitting (model memorized training data but can’t generalize).\n",
    "\n",
    "- If both are low → well-fitted model.\n",
    "\n",
    "Use plots to visualize predictions against true data to reinforce these observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1 - Change the number of epochs in the OverfittingModel and find the right epochs that reduces the overfitting issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 - Change the number of neurons in the hidden layers of the OverfittingModel and find the right model architecture that reduces the overfitting issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 3 - Change the layers of the OverfittingModel and find the right model architecture that reduces the overfitting issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 4 - Find advanced regularization techniques and apply those techniques to the \n",
    "# same OverfittingModel (i.e., do not change the original OverfittingModel's architecture) and derive a better model\n",
    "# with the help of the advanced regularization techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 5 - Impact of Noise\n",
    "\n",
    "# Increase or decrease the noise in the synthetic dataset.\n",
    "\n",
    "# How does the level of noise influence the model's ability to generalize?\n",
    "\n",
    "# Which model handles noisy data better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 6 - Early Stopping\n",
    "\n",
    "# Try training the same model for 100, 500, and 1000 epochs.\n",
    "\n",
    "# At which point does the model start to overfit?\n",
    "\n",
    "# Can you suggest a stopping criterion to prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 7: Regularization\n",
    "\n",
    "# Add a dropout layer or use L2 regularization in your model.\n",
    "\n",
    "# How does it affect training and validation losses?\n",
    "\n",
    "# Can you explain why regularization helps prevent overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 8: Think and Reflect\n",
    "\n",
    "# Suppose you build a highly accurate model on training data, but it performs poorly in real-world data.\n",
    "\n",
    "# What could be the reasons?\n",
    "\n",
    "# How would you identify and fix the issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📘 Summary:\n",
    "\n",
    "Underfitting occurs when the model is too simple or not trained enough.\n",
    "\n",
    "Overfitting occurs when the model is too complex or trained too long.\n",
    "\n",
    "Achieving good generalization requires:\n",
    "\n",
    " - Appropriate model complexity\n",
    "\n",
    " - Proper training duration\n",
    "\n",
    " - Regularization techniques (like dropout or weight decay)\n",
    "\n",
    " - Enough and diverse data\n",
    "\n",
    "Understanding the balance between bias and variance is key to building good ML models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
