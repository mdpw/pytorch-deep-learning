{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s--hI2jtGoj2"
      },
      "outputs": [],
      "source": [
        "# Sumani\n",
        "# https://www.linkedin.com/in/sumanaruban/\n",
        "# https://github.com/Sumanaruban\n",
        "# 29-7-2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAw5Vq5kGoj4"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is a continuation of the previous Jupyter notebook [02_fully_connected_mnist.ipynb](./02_fully_connected_mnist.ipynb), where we built and trained a fully connected neural network to classify handwritten digits from the MNIST dataset using PyTorch. Having understood the fundamental steps involved in model development, this notebook provides a series of incremental exercises designed to deepen your understanding of various aspects of neural network training and optimization.\n",
        "\n",
        "Each exercise introduces a small modification to the existing model or training process. These modifications will help you explore the effects of different model architectures, activation functions, optimizers, learning rates, regularization techniques, data augmentation, loss functions, and evaluation metrics. By completing these exercises, you will gain hands-on experience in tuning neural networks and improving model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56SXNUtvGoj5"
      },
      "source": [
        "# How to Use This Notebook\n",
        "1. **Review the Previous Notebook**: Ensure you are familiar with the steps and code in the previous notebook, as this notebook builds upon that foundation.\n",
        "2. **Complete the Exercises**: Work through each exercise one by one. Make the specified changes to the model or training process and run the cells to see the effects.\n",
        "3. **Document Your Observations**: For each exercise, take note of how the changes impact the model's training and evaluation metrics. Provide explanations for any improvements or deteriorations in performance.\n",
        "4. **Experiment and Explore**: Feel free to experiment further by combining different techniques or exploring additional modifications beyond the provided exercises.\n",
        "\n",
        "By the end of this notebook, you will have a deeper understanding of how various factors influence the training and performance of neural networks, equipping you with the knowledge and skills to effectively tune and optimize models for real-world applications."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "ttbkM258JCl7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformation to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert the images to tensors\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the pixel values with mean and std\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnZ7GuCsJLnM",
        "outputId": "41b97516-06f1-4b5a-e345-ddad2286ed12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.8MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.70MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.4MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.53MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the neural network model\n",
        "class FullyConnectedNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FullyConnectedNet, self).__init__()\n",
        "\n",
        "        # First Layer\n",
        "        self.layer_1 = nn.Linear(28*28, 512)\n",
        "        self.activation_1 = nn.ReLU() # ReLU activation\n",
        "\n",
        "        # Second Layer\n",
        "        self.layer_2 = nn.Linear(512, 256)\n",
        "        self.activation_2 = nn.ReLU() # ReLU activation\n",
        "\n",
        "        # Third layer\n",
        "        self.layer_3 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the image\n",
        "        x = x.view(-1, 28*28)\n",
        "\n",
        "        # Calling the first layer\n",
        "        x = self.layer_1(x)\n",
        "        x = self.activation_1(x)\n",
        "\n",
        "        x = self.layer_2(x)\n",
        "        x = self.activation_2(x)\n",
        "\n",
        "        # Calling the second layer\n",
        "        x = self.layer_3(x)  # Output layer\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FullyConnectedNet().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df6TEn7jJbAb",
        "outputId": "40a0322e-d2fe-400b-976f-680ec346b05f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FullyConnectedNet(\n",
            "  (layer_1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (activation_1): ReLU()\n",
            "  (layer_2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (activation_2): ReLU()\n",
            "  (layer_3): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(model, input_size=(1, 784))"
      ],
      "metadata": {
        "id": "6fVGu0TdUPv5",
        "outputId": "73967407-cf78-42ed-fa89-99da29eef509",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                  [-1, 512]         401,920\n",
            "              ReLU-2                  [-1, 512]               0\n",
            "            Linear-3                  [-1, 256]         131,328\n",
            "              ReLU-4                  [-1, 256]               0\n",
            "            Linear-5                   [-1, 10]           2,570\n",
            "================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 2.04\n",
            "Estimated Total Size (MB): 2.06\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "FAPU9XxtUWcE",
        "outputId": "a0fa8d22-fcef-445b-e064-a23d1f56abb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torchviz) (2.6.0+cu124)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from torchviz) (0.21)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torchviz)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torchviz)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torchviz)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torchviz)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torchviz)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torchviz)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torchviz)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchviz\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "import torch\n",
        "\n",
        "x = torch.randn(1, 784)\n",
        "y = model(x)\n",
        "\n",
        "make_dot(y, params=dict(model.named_parameters())).render(\"nn_mnist_graph\", format=\"png\")"
      ],
      "metadata": {
        "id": "IkADJZa-VQm1",
        "outputId": "fcc142c3-edf6-4526-8972-b8bb20f07d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nn_mnist_graph.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr8Ia7xSGoj5"
      },
      "source": [
        "## Exercise 1: Modify the Model Architecture\n",
        "\n",
        "    Add a Hidden Layer: Add an additional hidden layer with 256 neurons between the existing layers. Re-train the model and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JEjpFXXGoj6"
      },
      "source": [
        "# Exercise 2: Change the Activation Function\n",
        "\n",
        "    Use Different Activation Functions: Replace the ReLU activation function with other activation functions such as Sigmoid or Tanh. Observe the impact on training and evaluation metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vL4yBL_Goj6"
      },
      "source": [
        "# Exercise 3: Change the Optimizer\n",
        "\n",
        "    Use Adam Optimizer: Replace the SGD optimizer with the Adam optimizer. Compare the training speed and final accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sEa3839Goj6"
      },
      "source": [
        "# Exercise 4: Adjust the Learning Rate\n",
        "\n",
        "    Experiment with Learning Rates: Try different learning rates (e.g., 0.1, 0.001, 0.0001) with the SGD and Adam optimizers. Record the effects on the model's training performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSr3XqDKGoj6"
      },
      "source": [
        "# Exercise 5: Implement Dropout\n",
        "\n",
        "    Add Dropout Layers: Introduce dropout layers with a dropout probability of 0.5 to the network. Check if the model's performance improves by reducing overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oonNPhvPGoj7"
      },
      "source": [
        "# Exercise 6: Batch Normalization\n",
        "\n",
        "    Add Batch Normalization: Incorporate batch normalization layers into the network and observe any changes in training stability and speed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PVXUUoCGoj7"
      },
      "source": [
        "# Exercise 7: Data Augmentation\n",
        "\n",
        "    Apply Data Augmentation: Implement data augmentation techniques like random rotations, shifts, and flips to the training dataset. Evaluate the model's robustness to these transformations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNl0Y-xXGoj7"
      },
      "source": [
        "# Exercise 8: Learning Rate Scheduling\n",
        "\n",
        "    Implement Learning Rate Scheduling: Use a learning rate scheduler to decrease the learning rate during training. Compare the training process and model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciClYELNGoj7"
      },
      "source": [
        "# Exercise 9: Change the Loss Function\n",
        "\n",
        "    Use Different Loss Functions: Experiment with different loss functions such as Mean Squared Error (MSE) and observe how the choice of loss function affects model training and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoyBTtTCGoj7"
      },
      "source": [
        "# Exercise 10: Evaluate with Different Metrics\n",
        "\n",
        "    Implement Precision, Recall, and F1-Score: Extend the evaluation metrics to include precision, recall, and F1-score. Analyze the model's performance using these metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kAsINAtGoj8"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "These exercises will help you to understand the impact of different neural network architectures, optimization techniques, and evaluation metrics on the model's performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}